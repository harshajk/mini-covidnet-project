{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From C:\\Users\\212733771\\AppData\\Local\\Temp\\ipykernel_23352\\1348540267.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.test.is_gpu_available()\n","#tf.test.is_built_with_cuda()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import argparse\n","import os\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras \n","from imutils import paths\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.callbacks import (\n","    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",")\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import to_categorical\n","from keras import backend as K\n","\n","\n","from model_mobile import get_model\n","#from utils import Metrics  # Abhi \n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def focal_loss(y_true, y_pred):\n","    gamma = 5\n","    alpha = 0.25\n","    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n","    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n","    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n","DATA_DIR = 'C:/Users/212733771/Documents/Covid-Ultrasound/selected_frames/'\n","MODEL_DIR = 'C:/Users/212733771/Documents/Covid-Ultrasound/models'\n","FOLD = 0\n","LR = 1e-5\n","EPOCHS = 50\n","BATCH_SIZE = 16\n","TRAINABLE_BASE_LAYERS = 1\n","IMG_WIDTH, IMG_HEIGHT = (224,224)\n","NUM_CH = 3"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["model_name = 'pocus_fold_{0}'\n","plot_path = 'pocus_fold_{0}'\n","\n","if not os.path.exists(MODEL_DIR):\n","    os.makedirs(MODEL_DIR)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["covid\n","165\n","regular\n","83\n","pneumonia\n","267\n","covid\n","187\n","regular\n","126\n","pneumonia\n","173\n","covid\n","404\n","regular\n","122\n","pneumonia\n","392\n","covid\n","458\n","regular\n","83\n","pneumonia\n","81\n","covid\n","177\n","regular\n","98\n","pneumonia\n","352\n"]}],"source":["train_val_test={}\n","label_dict = {'cov':'covid','reg':'regular','pneu':'pneumonia'}\n","for test_train_dir in os.listdir(DATA_DIR):\n","    #print(test_train_dir)\n","    save_image_dir_foldwide = os.path.join(DATA_DIR,test_train_dir)\n","    label_flod={}\n","    # label_flod.append(test_train_dir)\n","    for key,label_folder in label_dict.items():\n","        print(label_folder)\n","        fold_path = os.path.join(save_image_dir_foldwide,label_folder)\n","        print(len(os.listdir(fold_path)))\n","        # label_flod.append(os.listdir(fold_path))\n","        label_flod[key]=[os.path.join(fold_path, f) for f in os.listdir(fold_path)] #os.listdir(fold_path)\n","    train_val_test[test_train_dir] = label_flod"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train_test_1\n","cov\n","165\n","reg\n","83\n","pneu\n","267\n","train_test_2\n","cov\n","187\n","reg\n","126\n","pneu\n","173\n","train_test_3\n","cov\n","404\n","reg\n","122\n","pneu\n","392\n","train_test_4\n","cov\n","458\n","reg\n","83\n","pneu\n","81\n","train_test_5\n","cov\n","177\n","reg\n","98\n","pneu\n","352\n","\n","Number of training samples: 1919 \n","Number of testing samples: 627\n"]}],"source":["train_folders=['train_test_1','train_test_2','train_test_3']\n","val_folders=['train_test_4']\n","test_folders=['train_test_5']\n","train_path=[]\n","train_data=[]\n","train_labels=[]\n","val_path=[]\n","val_data=[]\n","val_labels=[]\n","test_path=[]\n","test_data=[]\n","test_labels=[]\n","for path_key,folder in train_val_test.items():\n","    print(path_key)\n","    for type_key,paths in folder.items():\n","        print(type_key)\n","        print(len(paths))\n","        if (path_key in train_folders):\n","           train_path+= paths\n","           for imagePath in paths:\n","                image_org = np.load(imagePath,allow_pickle=False)\n","                assert image_org.shape[0] == 3\n","                image=np.zeros(shape=(IMG_WIDTH, IMG_HEIGHT,image_org.shape[0])).astype(image_org.dtype)\n","                for i in range(len(image_org)):\n","                    # image[i] = cv2.cvtColor(image[i], cv2.COLOR_BGR2RGB)  \n","                    image[:,:,i] = cv2.resize(cv2.cvtColor(image_org[i], cv2.COLOR_BGR2GRAY), (IMG_WIDTH, IMG_HEIGHT)) \n","                train_labels.append(type_key)\n","                train_data.append(image)                      \n","        if (path_key in val_folders):\n","           val_path+= paths\n","           for imagePath in paths:\n","                image_org = np.load(imagePath,allow_pickle=False)\n","                assert image_org.shape[0] == 3\n","                image=np.zeros(shape=(IMG_WIDTH, IMG_HEIGHT,image_org.shape[0])).astype(image_org.dtype)\n","                for i in range(len(image_org)):\n","                    # image[i] = cv2.cvtColor(image[i], cv2.COLOR_BGR2RGB)  \n","                    image[:,:,i] = cv2.resize(cv2.cvtColor(image_org[i], cv2.COLOR_BGR2GRAY), (IMG_WIDTH, IMG_HEIGHT)) \n","                val_labels.append(type_key)\n","                val_data.append(image)             \n","        if (path_key in test_folders):\n","           test_path+= paths   \n","           for imagePath in paths:\n","                image_org = np.load(imagePath,allow_pickle=False)\n","                assert image_org.shape[0] == 3\n","                image=np.zeros(shape=(IMG_WIDTH, IMG_HEIGHT,image_org.shape[0])).astype(image_org.dtype)\n","                for i in range(len(image_org)):\n","                    # image[i] = cv2.cvtColor(image[i], cv2.COLOR_BGR2RGB)  \n","                    image[:,:,i] = cv2.resize(cv2.cvtColor(image_org[i], cv2.COLOR_BGR2GRAY), (IMG_WIDTH, IMG_HEIGHT)) \n","                test_labels.append(type_key)\n","                test_data.append(image)                     \n","\n","print(\n","    '\\nNumber of training samples: '+str(len(train_labels))+' \\n'\n","    'Number of testing samples: '+str(len(test_labels))+''\n",")\n","\n","train_data = np.array(train_data)\n","test_data = np.array(test_data)\n","val_data = np.array(val_data)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["assert len(set(train_labels)) == len(set(test_labels)), (\n","    'Something went wrong. Some classes are only in train or test data.'\n",")  # yapf: disable\n","\n","train_data = (train_data-train_data.mean()) / train_data.std()\n","test_data = (test_data-test_data.mean()) / test_data.std()\n","val_data = (val_data-val_data.mean()) / val_data.std()\n","train_labels_text = np.array(train_labels)\n","test_labels_text = np.array(test_labels)\n","val_labels_text = np.array(val_labels)\n","\n","num_classes = len(set(train_labels))\n","\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","lb.fit(train_labels_text)\n","train_labels = lb.transform(train_labels_text)\n","lb.fit(test_labels_text)\n","test_labels = lb.transform(test_labels_text)\n","lb.fit(val_labels_text)\n","val_labels = lb.transform(val_labels_text)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1919, 224, 224, 3)\n","(627, 224, 224, 3)\n","(622, 224, 224, 3)\n","(1919, 3)\n","(627, 3)\n","(622, 3)\n"]}],"source":["print(train_data.shape)\n","print(test_data.shape)\n","print(val_data.shape)\n","print(train_labels.shape)\n","print(test_labels.shape)\n","print(val_labels.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Class mappings are: ['cov' 'pneu' 'reg']\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"]}],"source":["if num_classes == 2:\n","    train_labels = to_categorical(train_labels, num_classes=num_classes)\n","    test_labels = to_categorical(test_labels, num_classes=num_classes)\n","\n","trainX = train_data\n","trainY = train_labels\n","testX = test_data\n","testY = test_labels\n","valX = val_data\n","valY = val_labels\n","print('Class mappings are:', lb.classes_)\n","\n","# initialize the training data augmentation object\n","trainAug = ImageDataGenerator(\n","    rotation_range=10,\n","    fill_mode='nearest',\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1\n",")\n","\n","# Load the VGG16 network\n","model = get_model(\n","    input_size=(IMG_WIDTH, IMG_HEIGHT, 3), num_classes=num_classes\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["93"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["num_layers = len(model.layers)\n","num_layers"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\212733771\\AppData\\Local\\Temp\\ipykernel_23352\\1475550663.py:23: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","119/119 [==============================] - ETA: 0s - loss: 2.1159WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 64s 508ms/step - loss: 2.1159 - lr: 1.0000e-05\n","Epoch 2/50\n","119/119 [==============================] - ETA: 0s - loss: 1.6649WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 473ms/step - loss: 1.6649 - lr: 1.0000e-05\n","Epoch 3/50\n","119/119 [==============================] - ETA: 0s - loss: 1.3238WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 466ms/step - loss: 1.3238 - lr: 1.0000e-05\n","Epoch 4/50\n","119/119 [==============================] - ETA: 0s - loss: 0.9910WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 55s 464ms/step - loss: 0.9910 - lr: 1.0000e-05\n","Epoch 5/50\n","119/119 [==============================] - ETA: 0s - loss: 0.6966WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 58s 489ms/step - loss: 0.6966 - lr: 1.0000e-05\n","Epoch 6/50\n","119/119 [==============================] - ETA: 0s - loss: 0.7717WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 60s 501ms/step - loss: 0.7717 - lr: 1.0000e-05\n","Epoch 7/50\n","119/119 [==============================] - ETA: 0s - loss: 0.6632WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 59s 493ms/step - loss: 0.6632 - lr: 1.0000e-05\n","Epoch 8/50\n","119/119 [==============================] - ETA: 0s - loss: 0.5969WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 57s 474ms/step - loss: 0.5969 - lr: 1.0000e-05\n","Epoch 9/50\n","119/119 [==============================] - ETA: 0s - loss: 0.5606WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 59s 497ms/step - loss: 0.5606 - lr: 1.0000e-05\n","Epoch 10/50\n","119/119 [==============================] - ETA: 0s - loss: 0.4497WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 61s 514ms/step - loss: 0.4497 - lr: 1.0000e-05\n","Epoch 11/50\n","119/119 [==============================] - ETA: 0s - loss: 0.4058WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 470ms/step - loss: 0.4058 - lr: 1.0000e-05\n","Epoch 12/50\n","119/119 [==============================] - ETA: 0s - loss: 0.4215WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 59s 497ms/step - loss: 0.4215 - lr: 1.0000e-05\n","Epoch 13/50\n","119/119 [==============================] - ETA: 0s - loss: 0.2914WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 470ms/step - loss: 0.2914 - lr: 1.0000e-05\n","Epoch 14/50\n","119/119 [==============================] - ETA: 0s - loss: 0.3504WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 69s 575ms/step - loss: 0.3504 - lr: 1.0000e-05\n","Epoch 15/50\n","119/119 [==============================] - ETA: 0s - loss: 0.2712WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 58s 485ms/step - loss: 0.2712 - lr: 1.0000e-05\n","Epoch 16/50\n","119/119 [==============================] - ETA: 0s - loss: 0.3019WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 57s 474ms/step - loss: 0.3019 - lr: 1.0000e-05\n","Epoch 17/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1798WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 472ms/step - loss: 0.1798 - lr: 1.0000e-05\n","Epoch 18/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1957WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.1957 - lr: 1.0000e-05\n","Epoch 19/50\n","119/119 [==============================] - ETA: 0s - loss: 0.2274WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.2274 - lr: 1.0000e-05\n","Epoch 20/50\n","119/119 [==============================] - ETA: 0s - loss: 0.2192WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.2192 - lr: 1.0000e-05\n","Epoch 21/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1496WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 468ms/step - loss: 0.1496 - lr: 1.0000e-05\n","Epoch 22/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1361WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.1361 - lr: 1.0000e-05\n","Epoch 23/50\n","119/119 [==============================] - ETA: 0s - loss: 0.2433WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.2433 - lr: 1.0000e-05\n","Epoch 24/50\n","119/119 [==============================] - ETA: 0s - loss: 0.2529WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 466ms/step - loss: 0.2529 - lr: 1.0000e-05\n","Epoch 25/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1461WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 466ms/step - loss: 0.1461 - lr: 1.0000e-05\n","Epoch 26/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1291WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.1291 - lr: 1.0000e-05\n","Epoch 27/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1256WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 471ms/step - loss: 0.1256 - lr: 1.0000e-05\n","Epoch 28/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1052WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 57s 476ms/step - loss: 0.1052 - lr: 1.0000e-05\n","Epoch 29/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0814WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 57s 472ms/step - loss: 0.0814 - lr: 1.0000e-05\n","Epoch 30/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1169WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 470ms/step - loss: 0.1169 - lr: 1.0000e-05\n","Epoch 31/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1080WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 57s 473ms/step - loss: 0.1080 - lr: 1.0000e-05\n","Epoch 32/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1525WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 57s 473ms/step - loss: 0.1525 - lr: 1.0000e-05\n","Epoch 33/50\n","119/119 [==============================] - ETA: 0s - loss: 0.1144WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 469ms/step - loss: 0.1144 - lr: 1.0000e-05\n","Epoch 34/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0761WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 57s 474ms/step - loss: 0.0761 - lr: 1.0000e-05\n","Epoch 35/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0740WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 58s 488ms/step - loss: 0.0740 - lr: 1.0000e-05\n","Epoch 36/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0771WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 58s 485ms/step - loss: 0.0771 - lr: 1.0000e-05\n","Epoch 37/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0660WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.0660 - lr: 1.0000e-05\n","Epoch 38/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0633WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.0633 - lr: 1.0000e-05\n","Epoch 39/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0522WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.0522 - lr: 1.0000e-05\n","Epoch 40/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0539WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 466ms/step - loss: 0.0539 - lr: 1.0000e-05\n","Epoch 41/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 468ms/step - loss: 0.0594 - lr: 1.0000e-05\n","Epoch 42/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0513WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.0513 - lr: 1.0000e-05\n","Epoch 43/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 467ms/step - loss: 0.0609 - lr: 1.0000e-05\n","Epoch 44/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0357WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 470ms/step - loss: 0.0357 - lr: 1.0000e-05\n","Epoch 45/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0260WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 471ms/step - loss: 0.0260 - lr: 1.0000e-05\n","Epoch 46/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0411WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 472ms/step - loss: 0.0411 - lr: 1.0000e-05\n","Epoch 47/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0768WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 57s 475ms/step - loss: 0.0768 - lr: 1.0000e-05\n","Epoch 48/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0480WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 468ms/step - loss: 0.0480 - lr: 1.0000e-05\n","Epoch 49/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0941WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 56s 471ms/step - loss: 0.0941 - lr: 1.0000e-05\n","Epoch 50/50\n","119/119 [==============================] - ETA: 0s - loss: 0.0560WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n","119/119 [==============================] - 62s 517ms/step - loss: 0.0560 - lr: 1.0000e-05\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x16b864f60d0>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Number of layers in model head (fresh weights), this is fixed in get_model.\n","#num_head_layers =30\n","# Freeze all VGG layers apart from the last layers (TRAINABLE_BASE_LAYERS)\n","#num_layers = len(model.layers)\n","#for ind, layer in enumerate(model.layers):\n","#    if ind < num_layers - num_head_layers - TRAINABLE_BASE_LAYERS:\n","#        layer.trainable = False\n","\n","checkpoint_path = os.path.join(MODEL_DIR, 'ep{epoch:03d}-loss{loss:.3f}.h5')\n","\n","checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, period=3, save_best_only=True, save_weights_only=False, mode='max')\n","csv_logger = CSVLogger(os.path.join(MODEL_DIR, '/fold_' + str(FOLD) + '_model_loss.csv'), separator=',', append=False)\n","addptiveLr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='min', min_delta=0.001, cooldown=0, min_lr=0)\n","es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=25)\n","tb = TensorBoard(os.path.join(MODEL_DIR, 'fold_' + str(FOLD) + '_tb') )\n","callback_list = [checkpoint,csv_logger,tb,es,addptiveLr]\n","# model.compile(optimizer=Adam(lr=1e-5), loss='mean_squared_error')\n","model.compile(optimizer=Adam(lr=1e-5), loss=focal_loss)\n","\n","\n","verbose =True\n","\n","model.fit_generator(\n","    trainAug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n","    steps_per_epoch=len(trainX) // BATCH_SIZE,\n","    validation_data=(valX, valY),\n","    validation_steps=len(valX) // BATCH_SIZE,\n","    epochs=EPOCHS,\n","    verbose = verbose,\n","    callbacks=callback_list\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAiMAAAGxCAYAAACwbLZkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGKklEQVR4nO3deXhU5f3+8XuWzGQPkD2QhABJwCDIohCUXVGgFi21Vq1Lq7UoVpFSFbu4tN9iXShSRWsV0B+t2ApaXAuVzQWVVXYIEkKALIQlK1nn/P4IGQkkkGUmJ8v7dV1zhTlzzswnTylz+5xnsRiGYQgAAMAkVrMLAAAAHRthBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEE6MAWLlwoi8WiAwcOmF1Kkxw4cEAWi0ULFy5s9LU7d+7U448/3mZ/d6A9IYwA6JB27typJ554gjACtAKEEQAAYCrCCIBzzJ8/X/3795evr6+6dOmi66+/Xrt27ap1zv79+/XjH/9YMTExcjqdioyM1NixY7Vlyxb3OStXrtSoUaMUGhoqPz8/xcXFafLkySopKTnv53fv3l3f+9739M4776hfv37y9fVVjx49NHfu3AbV/9lnn2ns2LEKCgqSv7+/hg0bpg8++MD9+sKFC3XDDTdIkkaPHi2LxdLk2z0Amo8wAqCWWbNm6c4771RKSoqWLl2q559/Xlu3blVqaqrS0tLc502YMEEbN27U008/rRUrVuill17SgAEDdPLkSUnV4zkmTpwoh8Oh+fPn6+OPP9ZTTz2lgIAAlZeXX7COLVu2aNq0aXrwwQf1zjvvaNiwYXrggQf07LPPnve6NWvWaMyYMcrPz9drr72mN998U0FBQbr22mv11ltvSZImTpyoP/3pT5KkF198UevWrdO6des0ceLEJrYagGYxAHRYCxYsMCQZ6enphmEYxokTJww/Pz9jwoQJtc47ePCg4XQ6jZtvvtkwDMPIy8szJBlz5syp973ffvttQ5KxZcuWRtcVHx9vWCyWc6696qqrjODgYKO4uNgwDMNIT083JBkLFixwnzN06FAjIiLCKCwsdB+rrKw0+vbta3Tr1s1wuVyGYRjGv//9b0OSsWrVqkbXB8Cz6BkB4LZu3TqdOnVKd9xxR63jsbGxGjNmjD755BNJUpcuXdSzZ08988wzmj17tjZv3iyXy1XrmksuuUQOh0N33323Xn/9de3fv79RtaSkpKh///61jt18880qKCjQpk2b6rymuLhYX331lX74wx8qMDDQfdxms+nWW2/VoUOHtGfPnkbVAcD7CCMA3I4dOyZJio6OPue1mJgY9+sWi0WffPKJrr76aj399NMaOHCgwsPDdf/996uwsFCS1LNnT/3vf/9TRESEpk6dqp49e6pnz556/vnnG1RLVFRUvcdq6jjbiRMnZBhGvfWf71oA5iGMAHALDQ2VJGVlZZ3z2pEjRxQWFuZ+Hh8fr9dee03Z2dnas2ePHnzwQc2bN0+//vWv3ecMHz5c7733nvLz8/Xll18qNTVV06ZN0+LFiy9YS3Z2dr3Hauo8W+fOnWW1WuutX1Kt3wFA60AYAeCWmpoqPz8/LVq0qNbxQ4cOaeXKlRo7dmyd1yUlJem3v/2tLr744jpvodhsNg0ZMkQvvviiJNV7m+VMO3bs0DfffFPr2D//+U8FBQVp4MCBdV4TEBCgIUOGaOnSpTp16pT7uMvl0qJFi9StWzclJSVJkpxOpyTVOg+AOexmFwCg9ejUqZN+97vf6dFHH9Vtt92mm266SceOHdMTTzwhX19fPfbYY5KkrVu36r777tMNN9ygxMREORwOrVy5Ulu3btUjjzwiSXr55Ze1cuVKTZw4UXFxcSotLdX8+fMlSVdeeeUFa4mJidH3v/99Pf7444qOjtaiRYu0YsUK/fnPf5a/v3+9182aNUtXXXWVRo8erRkzZsjhcGjevHnavn273nzzTVksFklS3759JUmvvPKKgoKC5Ovrq4SEhHp7XQB4kdkjaAGY5+zZNDVeffVVo1+/fobD4TBCQkKMSZMmGTt27HC/npOTY9xxxx1G7969jYCAACMwMNDo16+f8Ze//MWorKw0DMMw1q1bZ1x//fVGfHy84XQ6jdDQUGPkyJHGsmXLLlhXfHy8MXHiROPtt982UlJSDIfDYXTv3t2YPXt2rfPqmk1jGIbx6aefGmPGjDECAgIMPz8/Y+jQocZ77713zufMmTPHSEhIMGw2W53vA6BlWAzDMEzOQwBQS/fu3dW3b1+9//77ZpcCoAUwZgQAAJiKMAIAAEzFbRoAAGAqekYAAICpCCMAAMBUhBEAAGCqNrHomcvl0pEjRxQUFOResAgAALRuhmGosLBQMTExslrr7/9oE2HkyJEjio2NNbsMAADQBJmZmerWrVu9r7eJMBIUFCSp+pcJDg42uRoAANAQBQUFio2NdX+P16dNhJGaWzPBwcGEEQAA2pgLDbFgACsAADAVYQQAAJiKMAIAAEzVJsaMAADQkgzDUGVlpaqqqswupVWz2Wyy2+3NXnaDMAIAwBnKy8uVlZWlkpISs0tpE/z9/RUdHS2Hw9Hk9yCMAABwmsvlUnp6umw2m2JiYuRwOFhssx6GYai8vFxHjx5Venq6EhMTz7uw2fkQRgAAOK28vFwul0uxsbHy9/c3u5xWz8/PTz4+PsrIyFB5ebl8fX2b9D4MYAUA4CxN/S/8jsgTbUVrAwAAUxFGAACAqQgjAAC0A6NGjdK0adPMLqNJCCMAAMBUHTqMvLP5kH7zzjZtzDhudikAAHRYHTqM/G9Xrv7x1UFtPnjS7FIAAK2UYRgqKa805WEYRpNqPnHihG677TZ17txZ/v7+Gj9+vNLS0tyvZ2Rk6Nprr1Xnzp0VEBCglJQUffjhh+5rb7nlFoWHh8vPz0+JiYlasGCBR9qyPh16nZHYztVzyA+dOGVyJQCA1upURZUu+v1/TfnsnU9eLX9H47+q77jjDqWlpWnZsmUKDg7Www8/rAkTJmjnzp3y8fHR1KlTVV5errVr1yogIEA7d+5UYGCgJOl3v/uddu7cqY8++khhYWHat2+fTp3y7vdkhw4j3Tr7SZIOnWDJXwBA+1ATQj7//HMNGzZMkvSPf/xDsbGxevfdd3XDDTfo4MGDmjx5si6++GJJUo8ePdzXHzx4UAMGDNDgwYMlSd27d/d6zR06jMR2qe4ZyTxOzwgAoG5+PjbtfPJq0z67sXbt2iW73a4hQ4a4j4WGhio5OVm7du2SJN1///265557tHz5cl155ZWaPHmy+vXrJ0m65557NHnyZG3atEnjxo3Tdddd5w413tKhx4yc2TPS1PtyAID2zWKxyN9hN+XRlH1x6vs+MwzD/X533XWX9u/fr1tvvVXbtm3T4MGD9de//lWSNH78eGVkZGjatGk6cuSIxo4dqxkzZjS9ARugQ4eRrp2qw0hxeZVOlFSYXA0AAM130UUXqbKyUl999ZX72LFjx7R371716dPHfSw2NlZTpkzR0qVL9atf/Up///vf3a+Fh4frjjvu0KJFizRnzhy98sorXq25Q9+m8fWxKSLIqdzCMh06UaIuAU3f/hgAgNYgMTFRkyZN0s9//nP97W9/U1BQkB555BF17dpVkyZNkiRNmzZN48ePV1JSkk6cOKGVK1e6g8rvf/97DRo0SCkpKSorK9P7779fK8R4Q4fuGZEYNwIAaH8WLFigQYMG6Xvf+55SU1NlGIY+/PBD+fj4SJKqqqo0depU9enTR9dcc42Sk5M1b948SZLD4dDMmTPVr18/jRgxQjabTYsXL/ZqvRajDQyWKCgoUEhIiPLz8xUcHOzR935g8Wb9Z8sRzRzfW78Y2dOj7w0AaFtKS0uVnp6uhIQE+fr6ml1Om3C+Nmvo9zc9I6fXGslkei8AAKbo8GHkuxk13KYBAMAMHT6MfDdmhJ4RAADM0OHDyJk9I21g+AwAAO1Ohw8j0SF+slqkskqXjhaVmV0OAKAV4D9OG84TbdXhw4jDblVUcPXoX8aNAEDHVjP1taSEW/cNVdNWNW3XFI1a9GzWrFlaunSpdu/eLT8/Pw0bNkx//vOflZycfN7r1qxZo+nTp2vHjh2KiYnRQw89pClTpjS5aE/r1sVfR/JLlXm8RAPjOptdDgDAJDabTZ06dVJubq4kyd/fv0lLsncEhmGopKREubm56tSpk2y2xu+jU6NRYWTNmjWaOnWqLr30UlVWVuo3v/mNxo0bp507dyogIKDOa9LT0zVhwgT9/Oc/16JFi/T555/r3nvvVXh4uCZPntzkwj2pW2c/fZ1OzwgAQIqKipIkdyDB+XXq1MndZk3VqDDy8ccf13q+YMECRUREaOPGjRoxYkSd17z88suKi4vTnDlzJEl9+vTRhg0b9Oyzz7aaMFKz1sgh1hoBgA7PYrEoOjpaERERqqhg37Lz8fHxaVaPSI1m7U2Tn58vSerSpUu956xbt07jxo2rdezqq6/Wa6+9poqKijrvMZWVlams7LvBpAUFBc0p84JYawQAcDabzeaRL1pcWJMHsBqGoenTp+uKK65Q37596z0vOztbkZGRtY5FRkaqsrJSeXl5dV4za9YshYSEuB+xsbFNLbNBWGsEAADzNDmM3Hfffdq6davefPPNC5579uCfmmlA9Q0KmjlzpvLz892PzMzMppbZIDU9I4dPnpLLxXQuAABaUpNu0/zyl7/UsmXLtHbtWnXr1u2850ZFRSk7O7vWsdzcXNntdoWGhtZ5jdPplNPpbEppTRIV7Cu71aKKKkM5haWKDvFrsc8GAKCja1TPiGEYuu+++7R06VKtXLlSCQkJF7wmNTVVK1asqHVs+fLlGjx4cLPmJHuS3WZVdCfWGgEAwAyNCiNTp07VokWL9M9//lNBQUHKzs5Wdna2Tp367gt85syZuu2229zPp0yZooyMDE2fPl27du3S/Pnz9dprr2nGjBme+y08wL17L+NGAABoUY0KIy+99JLy8/M1atQoRUdHux9vvfWW+5ysrCwdPHjQ/TwhIUEffvihVq9erUsuuUR/+MMfNHfu3FYzrbcGM2oAADBHo8aMNGT9+YULF55zbOTIkdq0aVNjPqrF0TMCAIA5OvzeNDW6daFnBAAAMxBGTnP3jLAKKwAALYowclq302EkK79UlVUuk6sBAKDjIIycFhHklMNmVZXLUFZ+qdnlAADQYRBGTrNaLerKjBoAAFocYeQMNdN7GTcCAEDLIYycoWbcCD0jAAC0HMLIGWJrpvey1ggAAC2GMHIGekYAAGh5hJEzxDJmBACAFkcYOUNNz0h2QanKK1lrBACAlkAYOUNYoEO+PlYZhnTkJLdqAABoCYSRM1gsFsaNAADQwggjZ2GtEQAAWhZh5Cyx7p4RwggAAC2BMHIWd8/IcW7TAADQEggjZ4ntQs8IAAAtiTBylu/GjNAzAgBASyCMnKVmzMjRwjKVVlSZXA0AAO0fYeQsnfx9FOCwSWJ6LwAALYEwchaLxcK4EQAAWhBhpA6MGwEAoOUQRurQjbVGAABoMYSROtT0jBxirREAALyOMFIHxowAANByCCN1YMwIAAAthzBSh5oxI8eLy1VcVmlyNQAAtG+EkTqE+Pko2NcuibVGAADwNsJIPRg3AgBAyyCM1OO73XsJIwAAeBNhpB6x7rVGuE0DAIA3EUbq8d2MGnpGAADwJsJIPb4bM0LPCAAA3kQYqUfN9F7GjAAA4F2EkXrU3KYpKK1U/qkKk6sBAKD9IozUI8BpV5cAhySm9wIA4E2EkfOIrdkwj3EjAAB4DWHkPBg3AgCA9xFGzqNbF3pGAADwNsLIeXTrzJLwAAB4G2HkPBgzAgCA9xFGzuPMMSOGYZhcDQAA7RNh5Dxq1hopLq/SyRLWGgEAwBsII+fh62NTeJBTEnvUAADgLYSRC2DcCAAA3kUYuQDWGgEAwLsIIxcQe3qtEW7TAADgHYSRC4gPDZAk7T9abHIlAAC0T4SRC0iKDJIk7c0pMrkSAADaJ8LIBSRGBEqS8orKdKK43ORqAABofwgjFxDgtKtrp+pxI3tzCk2uBgCA9ocw0gBJkdW9I3tzuVUDAICnEUYaoGbcSBo9IwAAeBxhpAES3YNYCSMAAHgaYaQBam7TpDGjBgAAjyOMNEDP8Oowcqy4XMeKykyuBgCA9oUw0gABTrt7B980BrECAOBRhJEGYhArAADeQRhpoMSa6b2MGwEAwKMIIw2UFMGMGgAAvIEw0kDu2zSMGQEAwKMIIw3UKyJQFot0vLhcecyoAQDAYwgjDeTnsCm2s78kbtUAAOBJhJFGYPEzAAA8jzDSCCwLDwCA5xFGGoGeEQAAPI8w0giJNdN7cwtlGIbJ1QAA0D4QRhqhV0SgrBbpZEmFjjKjBgAAjyCMNIKvj01xXapn1HCrBgAAzyCMNBKDWAEA8KxGh5G1a9fq2muvVUxMjCwWi959993znr969WpZLJZzHrt3725qzaZKYo8aAAA8yt7YC4qLi9W/f3/99Kc/1eTJkxt83Z49exQcHOx+Hh4e3tiPbhXYvRcAAM9qdBgZP368xo8f3+gPioiIUKdOnRp0bllZmcrKvhsgWlBQ0OjP85bEMzbMMwxDFovF5IoAAGjbWmzMyIABAxQdHa2xY8dq1apV5z131qxZCgkJcT9iY2NbqMoL6xEeIKtFKiitVG4hM2oAAGgur4eR6OhovfLKK1qyZImWLl2q5ORkjR07VmvXrq33mpkzZyo/P9/9yMzM9HaZDebrY1P30ABJDGIFAMATGn2bprGSk5OVnJzsfp6amqrMzEw9++yzGjFiRJ3XOJ1OOZ1Ob5fWZImRgdqfV6y9OUUantg2x74AANBamDK1d+jQoUpLSzPjoz2CQawAAHiOKWFk8+bNio6ONuOjPYK1RgAA8JxG36YpKirSvn373M/T09O1ZcsWdenSRXFxcZo5c6YOHz6sN954Q5I0Z84cde/eXSkpKSovL9eiRYu0ZMkSLVmyxHO/RQtzb5iXW8SMGgAAmqnRYWTDhg0aPXq0+/n06dMlSbfffrsWLlyorKwsHTx40P16eXm5ZsyYocOHD8vPz08pKSn64IMPNGHCBA+Ub46EsADZrBYVllYqp6BMUSG+ZpcEAECbZTHawPazBQUFCgkJUX5+fq2F08w05rnV2n+0WG/87DKNSGIQKwAAZ2vo9zd70zRRUgTjRgAA8ATCSBO5x42wRw0AAM1CGGki94yaXHpGAABoDsJIE9WsNbIvp3pGDQAAaBrCSBMlhAXIbrWosKxSWfmlZpcDAECbRRhpIofdqu5h7FEDAEBzEUaagUGsAAA0H2GkGRKZ3gsAQLMRRpohyT2jhp4RAACaijDSDDW3afblFDKjBgCAJiKMNEP3sAD52CwqLq/S4ZOnzC4HAIA2iTDSDD42qxJOz6hhECsAAE1DGGkm90qsDGIFAKBJCCPN9N2GefSMAADQFISRZnKvNcIeNQAANAlhpJlqbtOk5RTJ5WJGDQAAjUUYaabuof5y2Kw6VcGMGgAAmoIw0kx2m1U9wtmjBgCApiKMeMB3M2oYxAoAQGMRRjwgKYJBrAAANBVhxANYawQAgKYjjHhAclR1GNmXW6QqZtQAANAohBEPiOviL6fdqtIKlzKPl5hdDgAAbQphxANsVosSTy9+todbNQAANAphxEOSasaNZBNGAABoDMKIhySfDiP0jAAA0DiEEQ9JimJGDQAATUEY8ZCanpH9R4tVXukyuRoAANoOwoiHRIf4KshpV6XLUHpesdnlAADQZhBGPMRisbhv1TBuBACAhiOMeBAzagAAaDzCiAcls9YIAACNRhjxIGbUAADQeIQRD6qZUXPweIlKyitNrgYAgLaBMOJBoYFOhQU6ZBjVm+YBAIALI4x4WM0g1j0MYgUAoEEIIx7mnlHDuBEAABqEMOJhye61RrhNAwBAQxBGPIy1RgAAaBzCiIclnV5rJLugVPklFSZXAwBA60cY8bAgXx917eQnSdqbS+8IAAAXQhjxgpreEWbUAABwYYQRL2AlVgAAGo4w4gXJrDUCAECDEUa84My1RgzDMLkaAABaN8KIF/SKCJTVIp0oqdDRojKzywEAoFUjjHiBr49N3UMDJEl7s1n8DACA8yGMeMl3K7EybgQAgPMhjHjJdxvmFZhcCQAArRthxEvYowYAgIYhjHhJTc9IWk6hXC5m1AAAUB/CiJd0D/WXw2ZVSXmVDp88ZXY5AAC0WoQRL7HbrOoZwbLwAABcCGHEi5Jr9qhhRg0AAPUijHgRe9QAAHBhhBEvYo8aAAAujDDiRTUzavYfLVZFlcvkagAAaJ0II17UtZOfAhw2lVe5lHGs2OxyAABolQgjXmS1WpTovlXD4mcAANSFMOJl7nEjDGIFAKBOhBEvc8+oYRArAAB1Iox4WU3PCNN7AQCoG2HEy5Kiqhc+O3CsWKUVVSZXAwBA60MY8bLwQKc6+/vIZUj7chnECgDA2QgjXmaxWNzrjXCrBgCAcxFGWkByFDNqAACoD2GkBbh7RphRAwDAOQgjLSDZvWEeY0YAADgbYaQFJEVUh5HDJ0+psLTC5GoAAGhdGh1G1q5dq2uvvVYxMTGyWCx69913L3jNmjVrNGjQIPn6+qpHjx56+eWXm1JrmxXi76OoYF9J9I4AAHC2RoeR4uJi9e/fXy+88EKDzk9PT9eECRM0fPhwbd68WY8++qjuv/9+LVmypNHFtmXulVgZxAoAQC32xl4wfvx4jR8/vsHnv/zyy4qLi9OcOXMkSX369NGGDRv07LPPavLkyY39+DYrOTJQa/ce1R4GsQIAUIvXx4ysW7dO48aNq3Xs6quv1oYNG1RRUff4ibKyMhUUFNR6tHXJUcGS6BkBAOBsXg8j2dnZioyMrHUsMjJSlZWVysvLq/OaWbNmKSQkxP2IjY31dplexx41AADUrUVm01gsllrPDcOo83iNmTNnKj8/3/3IzMz0eo3e1isiUFaLlFdUrtzCUrPLAQCg1Wj0mJHGioqKUnZ2dq1jubm5stvtCg0NrfMap9Mpp9Pp7dJalJ/Dph7hgdqXW6QdRwoUkexrdkkAALQKXu8ZSU1N1YoVK2odW758uQYPHiwfHx9vf3yr0jemetzIjsP5JlcCAEDr0egwUlRUpC1btmjLli2SqqfubtmyRQcPHpRUfYvltttuc58/ZcoUZWRkaPr06dq1a5fmz5+v1157TTNmzPDMb9CG9O0aIknafrjtD8gFAMBTGn2bZsOGDRo9erT7+fTp0yVJt99+uxYuXKisrCx3MJGkhIQEffjhh3rwwQf14osvKiYmRnPnzu1Q03prpMRUh5EdWfSMAABQw2LUjCZtxQoKChQSEqL8/HwFBwebXU6T5Z+qUP8nlkuSvvn9OIX4d6zbVACAjqWh39/sTdOCQvx8FNfFX5K04wi9IwAASISRFte3a3Uy3E4YAQBAEmGkxdWMG2EQKwAA1QgjLSylZnovPSMAAEgijLS4mp6R/XnFKi6rNLkaAADMRxhpYeFBTkUF+8owpF1Z3KoBAIAwYgL3IFZWYgUAgDBihotqBrEeoWcEAADCiAnce9QQRgAAIIyYoWaPmrScQpVWVJlcDQAA5iKMmCA6xFddAhyqdBnam1NodjkAAJiKMGICi8XiXm+Exc8AAB0dYcQk7h18WfwMANDBEUZM8t0eNfSMAAA6NsKISfqe7hnZlVWgiiqXydUAAGAewohJ4rr4K8hpV3mlS98eLTK7HAAATEMYMYnValEfBrECAEAYMVNfBrECAEAYMVPNINYd9IwAADowwoiJalZi3XEkXy6XYXI1AACYgzBioh5hAXLarSour9KBY8VmlwMAgCkIIyay26zqE816IwCAjo0wYjL3uBEGsQIAOijCiMncM2oYxAoA6KAIIyarGcS6/Ui+DINBrACAjocwYrLEyEDZrRadLKnQ4ZOnzC4HAIAWRxgxmdNuU1JkkCRWYgUAdEyEkVagZhDrTgaxAgA6IMJIK/DduJGG9YzkFZXpX+szVVZZ5c2yAABoEXazC4CU4t4w78I9I6UVVfrJq19pd3ahvj1apJkT+ni7PAAAvIqekVagT3SwLBYpt7BMuYWl5z33sf/s0O7sQknSwi8OKDv//OcDANDaEUZaAX+HXT3DAyVJO85zq+bfGzL11oZMWSxSfKi/yipdmrsyraXKBADAKwgjrUTfmJodfOu+VbM7u0C/+892SdKDVybpmR/2lyT9a32mDuSxrw0AoO0ijLQS7kGsdUzvLSyt0L2LNqm0wqURSeG6b3QvXZbQRaOSw1XpMjR7xd6WLhcAAI8hjLQSF9UMYj1req9hGHpk6TbtzytWdIiv5tx4iaxWiyRpxrhkSdKyb45oJxvtAQDaKMJIK5Fyeo+aQydO6WRJufv4G+sy9MHWLNmtFr1w80B1CXC4X+vbNUTf6xctSXp2+Z6WLRgAAA8hjLQSIX4+iuviL0nuXo4tmSf1xw92SpIeGd9bg+I7n3Pdr8Yly2a1aOXuXK0/cLzlCgYAwEMII61IzUqs24/k62RJuab+Y5MqqgxdkxKlO69IqPOahLAA/WhwN0nS0x/vZrM9AECbQxhpRWpu1Ww9lK/p//pGh0+eUnyov56+oZ8sFku9190/NlEOu1XrD5zQ6j1HW6pcAAA8gjDSitSsxPrhtiyt3J0rh92qebcMVLCvz3mviw7x0+2p8ZKkp/+7Ry4XvSMAgLaDMNKK1PSM1GSJJ76f4j52IfeO6qUgp127sgr0/rYsb5UIAIDHEUZakfAgp6JDfCVJPxjQVT++NLbB13YOcOjnI3pIkmYv36OKKpdXagQAwNMII63Mk5P66ufDE/TH6/ued5xIXX52RYJCAxw6cKxE/95wyEsVAgDgWYSRVuaqiyL1m4kXyd/R+A2VA512TR3dS5L0/Cd7VVpR5enyAADwOMJIO3PL0Dh17eSnnIIyvbHugNnlAABwQYSRdsZpt+mBKxMlSfNWf6uC0gqTKwIA4PwII+3QDwZ0Vc/wAJ0sqdBf2EQPANDKEUbaIbvNqpnj+0iSFnx+QG9+fdDkigAAqB9hpJ268qJIPTC2+nbNb9/drjV7WZkVANA6EUbasWlXJuoHA7qqymVo6j82aVdWgdklAQBwDsJIO2axWDRr8sUaktBFRWWV+tnC9copKDW7LAAAaiGMtHNOu02v3DpYPcIDlJVfqp8tXK/iskqzywIAwI0w0gGE+Pto4R2XKTTAoR1HCnT/m5tVxWZ6AIBWgjDSQcSF+uvvtw+W027VJ7tz9eR7O2QYBBIAgPkIIx3IwLjO+suNl0iSXl+XofmfHzC1HgAAJMJIhzPh4mjNHN9bkvTHD3bqvzuyTa4IANDREUY6oLtH9NDNQ+JkGNIDizdrS+ZJs0sCAHRghJEOyGKx6Mnvp2hEUrhKK1z60d/W6cVV+1Re6TK7NABAB0QY6aDsNqtevHmARiaFq7zSpWf+u0fX/vUzbTp4wuzSAAAdDGGkAwvy9dHCn16qOTdeoi4BDu3JKdTkl77Q7/+zXYXs9gsAaCGEkQ7OYrHougFd9cn0kZo8sJsMQ3pjXYaumr1WyxncCgBoAYQRSJI6Bzj03I/66x93DVF8qL+yC0p19//bqHsWbWQJeQCAVxFGUMvlvcL032kjdM+onrJZLfpoe7aufG6Nlmw8ZHZpAIB2ijCCc/j62PTwNb313n1XqH+3EBWWVepX//6GXX8BAF5BGEG9LooJ1tJ7L9fVKZGSpNkr9ppcEQCgPSKM4LxsVot+fXVvWS3Sip05+oYF0gAAHkYYwQX1igjU9QO6SZKeo3cEAOBhhBE0yANjE2W3WrR271F9nX7c7HIAAO0IYQQNEhfqrx9dGitJenb5HhmGYXJFAID2oklhZN68eUpISJCvr68GDRqkTz/9tN5zV69eLYvFcs5j9+7dTS4a5vjlmF5y2K36Ov24Pt93zOxyAADtRKPDyFtvvaVp06bpN7/5jTZv3qzhw4dr/PjxOnjw4Hmv27Nnj7KystyPxMTEJhcNc0SH+OmWIXGS6B0BAHhOo8PI7Nmzdeedd+quu+5Snz59NGfOHMXGxuqll14673URERGKiopyP2w2W5OLhnnuGdVTfj42bck8qZW7c80uBwDQDjQqjJSXl2vjxo0aN25crePjxo3TF198cd5rBwwYoOjoaI0dO1arVq0677llZWUqKCio9UDrEBHkq9uHdZckPbd8r1wuekcAAM3TqDCSl5enqqoqRUZG1joeGRmp7Oy6N1WLjo7WK6+8oiVLlmjp0qVKTk7W2LFjtXbt2no/Z9asWQoJCXE/YmNjG1MmvOwXI3oo0GnXzqwCfcxmegCAZrI35SKLxVLruWEY5xyrkZycrOTkZPfz1NRUZWZm6tlnn9WIESPqvGbmzJmaPn26+3lBQQGBpBXpHODQnVck6PlP0jR7xV5dnRIlm7Xu//0BALiQRvWMhIWFyWazndMLkpube05vyfkMHTpUaWlp9b7udDoVHBxc64HW5c7hCQrx89G+3CIt++aw2eUAANqwRoURh8OhQYMGacWKFbWOr1ixQsOGDWvw+2zevFnR0dGN+Wi0MsG+PvrFyB6SpDn/S1NFlcvkigAAbVWjb9NMnz5dt956qwYPHqzU1FS98sorOnjwoKZMmSKp+hbL4cOH9cYbb0iS5syZo+7duyslJUXl5eVatGiRlixZoiVLlnj2N0GLu2NYd83/LF0Zx0q0ZOMh/fiyOLNLAgC0QY0OIzfeeKOOHTumJ598UllZWerbt68+/PBDxcfHS5KysrJqrTlSXl6uGTNm6PDhw/Lz81NKSoo++OADTZgwwXO/BUzh77DrnlG99If3d2ruJ2m6fmBXOe1M2QYANI7FaAMrVxUUFCgkJET5+fmMH2llSiuqNOqZ1couKNUT309xT/sFAKCh39/sTYNm8fWx6b4xvSRJL6zap2NFZSZXBABoawgjaLYfDY5VbBc/HS0s0/f++pk2ZpwwuyQAQBtCGEGzOexWzb/9UvUID1BWfqlu/Ns6zf8snb1rAAANQhiBRyRGBmnZfVdoYr9oVboMPfn+Tk395yYVllaYXRoAoJUjjMBjAp12vXDTAD1+7UXysVn04bZsff+Fz7U7u+F7CxmGobyiMva8AYAOhNk08IpNB0/ovn9s0pH8Uvn6WPXH6y7WDwd1q/Pc48Xl+nxfnj5NO6pP0/KUlV+qe0b11MPX9G7hqgEAntTQ72/CCLzmeHG5pr21RWv3HpUk/fjSWD3+/RRZLRZtOnjCHT62Hc7X2X8L/XxsWjdzjDr5O0yoHADgCYQRtAoul6EXVu3TX/63V4Yhde3kpxMl5Sopr6p1Xu+oIA1PDNOIpHD96cPd2pVVoIev6a17RvU0qXIAQHM19Pu7Sbv2Ag1ltVp0/9hEDYzrrPsXb9bhk6ckSWGBDl3RK0zDE8M1PDFMEcG+7mvuvKJMM/79jd5Yd0B3DU+Qj42hTQDQnhFG0CKuSAzTx9OGa923x9QrIlB9ooJltVrqPPfa/tF66qPdysov1Ufbs/X9/jEtXC0AoCXxn5xoMRFBvpp0SVelxITUG0QkyWm36dah1Xsdzf8svaXKAwCYhDCCVumWoXFy2K3aknmSFV0BoJ0jjKBVCgt06rpLqm/PzP+c3hEAaM8II2i1fnZFgiTp4+3Z7oGvAID2hzCCVqt3VLAu7xWqKpeh1784YHY5AAAvIYygVbvzdO/Im18fVHFZpcnVAAC8gTCCVm1UUoR6hAWosLRSb2881ODrXC5DL67ap7mfpLHPDQC0coQRtGpWq0U/vby7JGnB5+kNChYul6FH39mmZ/67R7NX7GUALAC0coQRtHqTB3VTsK9dB46VaOXu3POeaxiGHn9vhxavz3Qf+/PHu7X9cL63ywQANBFhBK2ev8Oum4bESZJeO88iaIZh6P8+2KU31mXIYpGeu6G/xl0UqYoqQ/cv3qyScsacAEBrRBhBm3B7anfZrBat239MO48U1HnOc8v36tXTYeVP11+syYO66c+T+ykq2Ff7jxbriWU7W7JkAEADEUbQJsR08tP4vlGS6l4Ebe4naXph1T5J0pOTUnTTZdU9KZ0DHJp9Y39ZLNJbGzL1wdaslisaANAghBG0GTXTfJdtOaKjhWXu4y+v+VazV+yVJP12Yh/dltq91nXDeobp3lE9JUmPLN2qQydKWqZgAECDEEbQZgyI66yBcZ1UXuXSoi8zJFXPsHnqo92SpF9fnay7hveo89ppVybpkthOKiyt1LTFW1RZ5WqxugEA50cYQZtSs0T8oi8ztODzdD3xXvU4kPvH9NLU0b3qvc7HZtXcHw9QoNOuDRkn9NeV+xr0eUcLy/T7/2zXVbPXaEvmyWbXDwA4F2EEbco1KVGKCfHVseJydxD5xYgeevCqpAteGxfqr/+7vq8k6a8r0/R1+vF6zy0srdDs5Xs08plVemNdhtJyi/SnD3Z55pcAANRCGEGbYrdZdfuw7u7ndwzrrkfG95bFYmnQ9ZMu6aofDOwqlyFNW7xZ+SUVtV4vq6zS/M/SNfKZ1Zq7cp9KyqvUv1uIHDarvj5wXBsO1B9gAABNQxhBm3PzkDiNTg7X1NE99di1FzU4iNR4clJfdQ/115H8Uj2ydKsMw1CVy9DSTYc09rk1evL9nTpeXK4eYQF6+ScD9e7Uy/WDgV0lVQ+WBQB4lsUwjFa/cUdBQYFCQkKUn5+v4OBgs8tBO/BN5klNfukLVboM/fTy7lr37THtzi6UJEUEOfXgVUm6YVA32W3VeX3/0SKNnb1GhiH9d9oIJUcFmVk+ALQJDf3+pmcEHVL/2E6acXWyJGnB5we0O7tQQb52PXRNstb8erRuuizOHUQkqUd4oHudk7/ROwIAHkUYQYd19/AeGndRpJx2q+4e0UOfPjRa947qJT+Hrc7zp4ysXqvkP98cYa0SAPAgu9kFAGaxWi36262DVOUyavWC1Kdft066oleYPtuXp1c/Tdfj309pgSrbDpfLkMWiRo/hAQDCCDo0i8Uiu63hX573jOqpz/blafH6g/rlmF4KDXR6sbrWqcpl6NCJEu3NKdLenEKl5RRqb06Rvj1apK6d/bTsvisU6OSfFgANx78YQCMM6xmqft1CtPVQvl7/4oCmj0s2uySvMwxD723N0qrdudqbU6hvjxaptKLuFWz3Hy3Wq5/u17QrL7zuCwDUIIwAjWCxWHTPyJ665x+b9Pq6DN09sme77wX4eHu27n9zc61jDrtVvcIDlRQZqMTIICVFBim7oFS/e3e7/r52v34yNF5hHbDXCEDTtO9/RQEvGJcSpR5hAdqfV6zFXx+sdz+c9qCyyqVnlu+RJE3sF61r+8UoKTJQ8aEBsllr394yDEP/3pCprYfy9cLKfYypAdBghBGgkWxWi34xsoceXrJNf/90v25NjZfTXvcMnMZa9+0x/WXFXmWeKFFcF38lhAUoPjRACWH+ig8NUHyov/wdLfd/27c3HtL+o8Xq7O+jp35wsYJ8feo912Kx6JFreuvmV7/SP77K0J1XJCi2i3+L1Qqg7SKMAE1w3YCumr1ir3IKyvSfzUf0o0tjm/V++3IL9dRHu/W/XbnuY1n5pfqqjv1zIoOdig8N0MC4znpgbGK9U5Gbq7SiSnP+lyZJmjq613mDSI1hvcI0PDFMn6bl6bnlezTnxwO8UhuA9oUwAjSB027TXVf00P99uEsvr/1Wkwd1O+e2RUMcLSzTnP/t1eL1mapyGbJZLbr5sjhd2z9Gh0+W6EBeiTKOFSv9WPXPkyUVyikoU05Bmb5OP67MEyV64aYBXplOu/CLA8ouKFXXTn76ydD4Bl/38DW99WnaZ/rPN0d094ieuiiGVZMBnB9hBGiim4bE6a8r07T/aLFW7MzWNX2jG3xtSXmlXv00XX9b862Ky6skSVddFKlHxvdWz/DA02d1Oee6kyXlOnCsRNsP5+uJ93bog61Z6h0ZpF+OTfTEr+SWX1Kheav2SZIevCpJvj4N733p2zVE1/aP0XvfHNHT/92thT+9zKO1AWh/WIEVaKJAp929g/BLq79VQ7Z5qnIZ+tf6TI1+drVmr9ir4tO7Ar9191D9/bbBZwSRunXyd+iS2E76ydB4PTmpryTpuRV79fH27Gb/Pmd6ee23KiitVFJkoK4f0LXR1//qqiTZrRat3nNUX+4/5tHaALQ/hBGgGe4Y1l2+PlZ9cyhf676t+0u3vNKlL77N06yPdumqv6zRQ0u2KqegTN06+2nuTQP0zr2Xa0iP0EZ/9k2XxemO02Fo+r+2aFdWQXN+FbecglIt+DxdkvTrq3s36fZT97AA3XRZnCTpqY92NyioAei4uE0DNENooFM3Do7V6+sy9NKabzWsV5gMw9CBYyVau/eo1u49qnX7j6nk9K0YSQr2teuXYxJ127Dmz8L57cQ+Ssst1Of7jumu1zdo2X2XN3tV2Oc/SVNphUuD4jvryj4RTX6fX47tpbc3HtKWzJP6744cXXN6o0EAOJvFaAP/ydLQLYgBM2QeL9GoZ1erymXoBwO6an3GcWUeP1XrnLBAp0YkhmlEUrhG945QiN+FZ6Y01MmSck168XNlHCvRZQldtOjOIXLYm9bpuf9oka76y9rq20m/SNVlCeeOW2mM55bv0V9X7lPP8AD9d9qIBu0BBKD9aOj3N/8yAM0U28Vf3+8fI0lauvmwMo+fko/NotQeoXr4mt764P4r9PWjYzX7xkt03YCuHg0iUvU4kldvG6xAp11fpx/XY8t2NPm2yHPL96rKZWhM74hmBxFJuntED3X299G3R4v19sZDzX4/AO0Tt2kAD5hxdbIKSysV08lXIxLDldozVAEtuEx8YmSQ5t50ie58fYPe/Pqg+kQH6bbU7o16j62HTuqDbVmyWKSHrvHMnjtBvj66b0yi/vD+Ts35X5quG9C1UTNzAHQM9IwAHtC1k59evX2wnpzUV1deFNmiQaTGmN6Revia3pKkJ97bqS/25TXq+qc/rl72/fpLuqp3lOduh/5kaJy6dvJTdkGpFn5xwGPvC6D9IIwA7cgvRvTQ9QO6qspl6N5/blLGseIGXfdZWp4+25cnH5tFD17l2R13nXabpp9+z3mr9im/pMKj7w+g7SOMAO2IxWLRrB9crP6xnXSypEJ3vr5BGzOOq7zSVe81hmHozx/vliTdMiTeK/vJXDegq5Ijg1RQWqmX1nzr8fdvK1buztE1c9bqj+/v1KkzZlgBHR2zaYB2KKegVN9/4TPlFJRJkpx2qy6J7aRLu3fRpQldNDCuk3uvmQ+2ZmnqPzcpwGHTmodGK6yZU4Pr88muHN35+gY57VbdlhqvMb0jNbh7Z/l0gBk2VS5Dz/9vr+au3Oc+Fh/qr2d+2N8jA4WB1qqh39+EEaCdSssp1HPL92r9geM6Vlxe6zWrReoTHaxLu3fRqj25yjhWogfGJnr8Fs2ZDMPQ7QvWa+3eo+5jQb52jUgK19jeERqVHKEuAQ6vfb5ZjheX64HFm/VpWvUYnusuidGX+48ru6BUFkv1wnkPXd3baxseAmYijACQVB0C9ucVa336ca0/cELrDxzXweMltc4JDXBozUOjFejlgbdllVX6ZFeuPtmVq1V7cnX8jJBksUgD4zprTO8IjUwKV1SIr4J9fZq8Zkpr8E3mSd37j006fPKUfH2seuoH/XTdgK7KP1Wh//tgp/61oXq6M70kaK8IIwDqlVNQqvUHjmvDgRPalVWgO69I0LiUll0htcpl6JtDJ7VyV64+2Z1b73L2vj5WBfn6KNjXrmA/HwX7+ijI164QPx8N6RGqq/pEtrpeBcMw9M+vD+qJZTtVXuVSQliAXvrJwHNmKa3ek6uZS7cpK59eErRPhBEAbcqRk6e0ak+uVu7K1foDx1VQWtmg6wIcNl2dEqVJA7rq8p6hXlnltaLKpez8UkWF+F5wjMup8ir99t3tWrKputfj6pRIPXNDfwX71r3YXUFphf74Pr0kaJ8IIwDatCqXoaKyShWcqlBBaYUKS2v+XP0zu6BUH23PqrX0fligU9f2j9Z1l3RVv24hslgav8nf2dbsParfvbtdB4+XyGa1KL6Lv3qEB6hneOAZPwPVJcChjGPFmrJok3ZlFchqkR6+prfuHtGjQXWc3Utye2p3PXRNsvwdrE2JtoswAqDdMwxDmw6e0Lubj+j9rUd04ow1TBLCAjTpkhhNHtitSdOVcwpK9eT7O/XB1ixJ1WNazvevZWd/H5VXulRcXqWwQIf+etNApfZs3G7MZ/eSdA/11zM39Nel3eklQdtEGAHQoVRUufRp2lG9u/mIlu/MVmlF9doqFos0Kilct6bGa2RShGzW8/dSVLkMLfoyQ8/+d48Kyypls1r002HdNe2qJBWVVurbo0Xaf7RI3x4tPv3nYh0++V3vzKD4znrx5oGKCvFt8u+yek+uHlmyzT3j5meXJ2jGuGTGkqDNIYwA6LCKyyq1fGe2lm467J5SK0mxXfx0y5B4/WhwbJ3TiLcfztej72zT1kP5kqT+sZ30p+v7KiUm5Lyfd6q8Sul5xSoqq9SAuE4eWTsl/1R1L8m/T28wmBAWoGdv6KdB8fSSoOE+TTuq3IIyXTeg6wWDuDcQRgBA0oG8Yv3jqwz9a8Mh5Z+qvo3jsFv1vYuj9ZPUeA2I7aSisko9t3yv3lh3QC6jev2Th6/prZsuizPlH/Azrdqdq0eWblVOQZksFumuKxL0q3HJbDiI86pyGXp2+R69tLp6xeNLYjvp2Rv6qVdEUIvWQRgBgDOUVlRp2TdH9P/WZWjb4Xz38ZSYYOUVlblXq510SYx+M7GPIoKafpvF0/JPVegP7+/U26d7SXqEB+iZH/bXoPjOJleG1ii/pEL3L96sNacXGPTzselURZUcdqumX5Wku65I8Mqss7oQRgCgHt9kntQb6zL03tYj7n17uof66w/X9dXwxHCTq6vfyt05emTJNuUWlslqkSZcHK2wQKd8fWzy9bFW/7Rb5eewydfHJqfdJpvVouKyShWWVaqotFLFZZUqKqtUYWmlisoqVFRWqfJKl3qGByqla4hSYoLVJyqY8Skm2n44Xy+v+Vb9uoXoJ0PjGzWjam9Ooe5+Y4MOHCuRr49VT/+wvy7t3lkzl27T6j3V4aR/bCc9+8N+Soz0fi8JYQQALuBEcbmWbDokw5BuTY1vE7c+8ksq9MT7O7R002GvfYbVIvWKCFTfmBBdFBOsvl2rf9a3Vgo8o7isUrNX7NWCz9PlOv3NHBbo0C9G9NRPhsZfMCD+d0e2pr+1RcXlVerayU+v3DbIPd7JMAy9vfGQnnx/pwpLK+WwWTXtqkTdPbyHV3tJCCMA0I598W2eNh44odLKKpVWuFRaUaVTFVUqO+PPpRVVqjKkIKddgU67An1P/zzjz0G+dlksFu3NLtT2I/nafjhfeUXldX6mr49VAQ67/J226p8OmwKc1T/9Tz/v2tlPfWOqe1hCvbTpoie5XIayCkrV2d/H1DVdlu/I1mPLdigrv1SSdGWfSO3NKXRv3RAW6NCUkT11y5BzQ4nLZWjOJ2ma+0maJCm1R6hevGVgnYO0s/NLNXPpVq2q6SXpFqJnb+jvtV4SwggAoNEMw1BuYZl2HMnX9sMF2n44XzuOFNSavtxQ0SG+SokJUd+uweobE6K+XUMUGew87yJwLpeh8iqXisoqdbSwTLmFZTp6+pFbWOo+lldYpvxTFYoK8VX30ADFh/p/9zMsQBFBtT/H5TJ0+OQp7c0p1N6cIqXlFiotp0j7cot0qqJKAQ6bbhgcq59e3l3xoQFNarumOHLylB5ftkPLd+ZIqp7x9YdJfTUqOUIVVS69s/mw/royzb24X3iQ83QoiZOvj02FpRV68K1v9L9d1df/9PLuenRCn/PO6DIMQ0s2HdYT7+3wei8JYQQA4DEFpRXKL6lQSXmVissrdaq8SsVlle7nJWVVKiyrVHpesXYcztf+vOI63ycs0KHoED+VV7pUVll1+mfNo0oVVZ75SvLzsSk+1F/dOvspt7BM+3KLVFJeVee5Vovct0UslupeiZ9dnqChPbp4ZBXfulRWufT6ugzNXr5HxeVVslstuntED/1yTOI5PR8VVS4t3XRIf125T4dOfBdKfnp5dy3ZeEjfHi2Ww27V/13XVzcMjm1wDdn5pXr0nW1auTtXknTf6F6acXWy535JEUYAACYqLK3QrqxCdw/LjiP5SsstUpWr4V85oQEOhQc53Y+IIF9FuP/sVJCvj7LyT+nAsRJlHCtWel6xMo6V6NCJEtX1MQ6bVT3CA5QYGaSkiMDqn5GBiu3iry/3H9Nrn6W7B3lK0kXRwfrZFQm6tn+0nHbPjSfaeuikHn1nm7Yfrt4cclB8Z/3p+ouVHHX+WyXllS4t2XRIL6zcV6unKirYVy/fOkiXxHZqdC2GYWjppsN6cfU+vT1lWJ23dpqDMAIAaFVKK6q0O7tQx4vL5LTb5LRb5bBbz/qzVc7Ts4KaesugvNKlwydP6cCxYh06cUrhgQ4lRgYpvov/Bd9zX26RFnyeriWbDrlX8Q0LdOgnQ+P140vjmrSybllllTYfPKkv9uXps3152px5UoYhBfvaNXNCH904OFbWRqxnU17p0tsbD+nvn+5X105+mn1j/2ZPRa9yGV5ZU4cwAgBAE50sKdc/vz6oN77IUHZBqft4aIBDSZFBSo4KOv2zuoflzJlGLpehXdkF+mLfMX22L09fpx/XqYrat4gmXRKj3068SOFBrX+Qb3MQRgAAaKaKKpc+2p6tBZ+na8vpHo26RIf4KikySP4Om75KP67jxbVnJIUFOnR5rzBd3jNMlyeGqWsnvxao3nyEEQAAPOhUeZX25RZpT06h9uYUak92odJyCnUkv/Scc/0dNg3tEaphPUN1RWKYkiODvDYYtjVr6Pd3kyZVz5s3T88884yysrKUkpKiOXPmaPjw4fWev2bNGk2fPl07duxQTEyMHnroIU2ZMqUpHw0AgCn8HDZd3C1EF3ervXFiQWmF0nIKtSe7SPmnKjS4e2f179ZJDnvLLLneHjQ6jLz11luaNm2a5s2bp8svv1x/+9vfNH78eO3cuVNxcXHnnJ+enq4JEybo5z//uRYtWqTPP/9c9957r8LDwzV58mSP/BIAAJgl2NdHg+K7sKNyMzT6Ns2QIUM0cOBAvfTSS+5jffr00XXXXadZs2adc/7DDz+sZcuWadeuXe5jU6ZM0TfffKN169Y16DO5TQMAQNvT0O/vRvUhlZeXa+PGjRo3blyt4+PGjdMXX3xR5zXr1q075/yrr75aGzZsUEVFRZ3XlJWVqaCgoNYDAAC0T40KI3l5eaqqqlJkZGSt45GRkcrOzq7zmuzs7DrPr6ysVF5eXp3XzJo1SyEhIe5HbGzDV5QDAABtS5NG15w9ItgwjPOOEq7r/LqO15g5c6by8/Pdj8zMzKaUCQAA2oBGDWANCwuTzWY7pxckNzf3nN6PGlFRUXWeb7fbFRoaWuc1TqdTTmf7XggGAABUa1TPiMPh0KBBg7RixYpax1esWKFhw4bVeU1qauo55y9fvlyDBw+Wj49PndcAAICOo9G3aaZPn65XX31V8+fP165du/Tggw/q4MGD7nVDZs6cqdtuu819/pQpU5SRkaHp06dr165dmj9/vl577TXNmDHDc78FAABosxq9zsiNN96oY8eO6cknn1RWVpb69u2rDz/8UPHx8ZKkrKwsHTx40H1+QkKCPvzwQz344IN68cUXFRMTo7lz57LGCAAAkMRy8AAAwEu8ss4IAACApxFGAACAqQgjAADAVIQRAABgqkbPpjFDzRhb9qgBAKDtqPnevtBcmTYRRgoLCyWJPWoAAGiDCgsLFRISUu/rbWJqr8vl0pEjRxQUFHTePXAaq6CgQLGxscrMzGTKcAugvVsW7d2yaO+WRXu3vKa0uWEYKiwsVExMjKzW+keGtImeEavVqm7dunnt/YODg/nL3IJo75ZFe7cs2rtl0d4tr7Ftfr4ekRoMYAUAAKYijAAAAFN16DDidDr12GOPyel0ml1Kh0B7tyzau2XR3i2L9m553mzzNjGAFQAAtF8dumcEAACYjzACAABMRRgBAACmIowAAABTEUYAAICpOnQYmTdvnhISEuTr66tBgwbp008/NbukdmHt2rW69tprFRMTI4vFonfffbfW64Zh6PHHH1dMTIz8/Pw0atQo7dixw5xi24FZs2bp0ksvVVBQkCIiInTddddpz549tc6hzT3npZdeUr9+/dyrUKampuqjjz5yv05be8+sWbNksVg0bdo09zHa27Mef/xxWSyWWo+oqCj3695q7w4bRt566y1NmzZNv/nNb7R582YNHz5c48eP18GDB80urc0rLi5W//799cILL9T5+tNPP63Zs2frhRde0Pr16xUVFaWrrrrKvSEiGmfNmjWaOnWqvvzyS61YsUKVlZUaN26ciouL3efQ5p7TrVs3PfXUU9qwYYM2bNigMWPGaNKkSe5/kGlr71i/fr1eeeUV9evXr9Zx2tvzUlJSlJWV5X5s27bN/ZrX2tvooC677DJjypQptY717t3beOSRR0yqqH2SZLzzzjvu5y6Xy4iKijKeeuop97HS0lIjJCTEePnll02osP3Jzc01JBlr1qwxDIM2bwmdO3c2Xn31VdraSwoLC43ExERjxYoVxsiRI40HHnjAMAz+bnvDY489ZvTv37/O17zZ3h2yZ6S8vFwbN27UuHHjah0fN26cvvjiC5Oq6hjS09OVnZ1dq+2dTqdGjhxJ23tIfn6+JKlLly6SaHNvqqqq0uLFi1VcXKzU1FTa2kumTp2qiRMn6sorr6x1nPb2jrS0NMXExCghIUE//vGPtX//fknebe82sWuvp+Xl5amqqkqRkZG1jkdGRio7O9ukqjqGmvatq+0zMjLMKKldMQxD06dP1xVXXKG+fftKos29Ydu2bUpNTVVpaakCAwP1zjvv6KKLLnL/g0xbe87ixYu1adMmrV+//pzX+LvteUOGDNEbb7yhpKQk5eTk6I9//KOGDRumHTt2eLW9O2QYqWGxWGo9NwzjnGPwDtreO+677z5t3bpVn3322Tmv0eaek5ycrC1btujkyZNasmSJbr/9dq1Zs8b9Om3tGZmZmXrggQe0fPly+fr61nse7e0548ePd//54osvVmpqqnr27KnXX39dQ4cOleSd9u6Qt2nCwsJks9nO6QXJzc09J/HBs2pGZdP2nvfLX/5Sy5Yt06pVq9StWzf3cdrc8xwOh3r16qXBgwdr1qxZ6t+/v55//nna2sM2btyo3NxcDRo0SHa7XXa7XWvWrNHcuXNlt9vdbUp7e09AQIAuvvhipaWlefXvd4cMIw6HQ4MGDdKKFStqHV+xYoWGDRtmUlUdQ0JCgqKiomq1fXl5udasWUPbN5FhGLrvvvu0dOlSrVy5UgkJCbVep829zzAMlZWV0dYeNnbsWG3btk1btmxxPwYPHqxbbrlFW7ZsUY8ePWhvLysrK9OuXbsUHR3t3b/fzRr+2oYtXrzY8PHxMV577TVj586dxrRp04yAgADjwIEDZpfW5hUWFhqbN282Nm/ebEgyZs+ebWzevNnIyMgwDMMwnnrqKSMkJMRYunSpsW3bNuOmm24yoqOjjYKCApMrb5vuueceIyQkxFi9erWRlZXlfpSUlLjPoc09Z+bMmcbatWuN9PR0Y+vWrcajjz5qWK1WY/ny5YZh0NbeduZsGsOgvT3tV7/6lbF69Wpj//79xpdffml873vfM4KCgtzfjd5q7w4bRgzDMF588UUjPj7ecDgcxsCBA91TIdE8q1atMiSd87j99tsNw6ieHvbYY48ZUVFRhtPpNEaMGGFs27bN3KLbsLraWpKxYMEC9zm0uef87Gc/c/+7ER4ebowdO9YdRAyDtva2s8MI7e1ZN954oxEdHW34+PgYMTExxg9+8ANjx44d7te91d4WwzCM5vWtAAAANF2HHDMCAABaD8IIAAAwFWEEAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJjq/wPVvIZbnSQWOwAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig2 = plt.figure()\n","plt.plot(model.history.history[\"loss\"], label=\"loss\")\n","plt.title(\"loss plot\")\n","# plt.plot(model.history.history[\"val_loss\"], label=\"val_loss\")\n","plt.legend()\n","fig2.savefig(os.path.join(MODEL_DIR, 'fold_' + str(FOLD) + '_loss_plot.png') )"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["39/39 [==============================] - 9s 211ms/step\n","Val data classification report sklearn:\n","              precision    recall  f1-score   support\n","\n","         cov       0.87      1.00      0.93       458\n","        pneu       1.00      1.00      1.00        81\n","         reg       0.94      0.19      0.32        83\n","\n","    accuracy                           0.89       622\n","   macro avg       0.94      0.73      0.75       622\n","weighted avg       0.90      0.89      0.86       622\n","\n"]}],"source":["predIdxs = model.predict(valX, batch_size=BATCH_SIZE)\n","predIdxs = np.argmax(predIdxs, axis=1)\n","print('Val data classification report sklearn:')\n","print(\n","    classification_report(\n","        valY.argmax(axis=1), predIdxs, target_names=lb.classes_\n","    )\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["627/627 [==============================] - 9s 13ms/step\n","Test data classification report sklearn:\n","              precision    recall  f1-score   support\n","\n","         cov       0.89      1.00      0.94       177\n","        pneu       0.98      0.99      0.99       352\n","         reg       0.97      0.70      0.82        98\n","\n","    accuracy                           0.95       627\n","   macro avg       0.95      0.90      0.92       627\n","weighted avg       0.95      0.95      0.95       627\n","\n"]}],"source":["predIdxs = model.predict(testX, batch_size=1)\n","predIdxs = np.argmax(predIdxs, axis=1)\n","print('Test data classification report sklearn:')\n","print(\n","    classification_report(\n","        testY.argmax(axis=1), predIdxs, target_names=lb.classes_\n","    )\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving COVID-19 detector model on {model_name} data...\n"]}],"source":["# serialize the model to disk\n","print('Saving COVID-19 detector model on {model_name} data...')\n","model.save(os.path.join(MODEL_DIR, model_name), save_format='h5')"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," conv1 (Conv2D)              (None, 112, 112, 32)      864       \n","                                                                 \n"," conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n"," n)                                                              \n","                                                                 \n"," conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n","                                                                 \n"," conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n","                                                                 \n"," conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n","                                                                 \n"," conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n","                                                                 \n"," conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n","                                                                 \n"," conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n","                                                                 \n"," conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n","                                                                 \n"," conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n","                                                                 \n"," conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n","                                                                 \n"," conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n","                                                                 \n"," conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n","                                                                 \n"," conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n","                                                                 \n"," conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n","                                                                 \n"," conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n","                                                                 \n"," conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n","                                                                 \n"," conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n","                                                                 \n"," conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n","                                                                 \n"," conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n","                                                                 \n"," conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n","                                                                 \n"," conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n","                                                                 \n"," conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n","                                                                 \n"," conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n","                                                                 \n"," conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n","                                                                 \n"," conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n","                                                                 \n"," conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n","                                                                 \n"," conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n","                                                                 \n"," conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n","                                                                 \n"," conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n","                                                                 \n"," conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n","                                                                 \n"," conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n","                                                                 \n"," conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n","                                                                 \n"," conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n","                                                                 \n"," conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n","                                                                 \n"," conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n","                                                                 \n"," conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n","                                                                 \n"," conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n","                                                                 \n"," conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n","                                                                 \n"," conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n","                                                                 \n"," conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n","                                                                 \n"," conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n","                                                                 \n"," conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n"," )                                                               \n","                                                                 \n"," conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n","                                                                 \n"," conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n","                                                                 \n"," conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n","                                                                 \n"," average_pooling2d (AverageP  (None, 1, 1, 1024)       0         \n"," ooling2D)                                                       \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               131200    \n","                                                                 \n"," batch_normalization (BatchN  (None, 128)              512       \n"," ormalization)                                                   \n","                                                                 \n"," p_re_lu (PReLU)             (None, 128)               128       \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 3,361,091\n","Trainable params: 3,338,947\n","Non-trainable params: 22,144\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["from keras.models import load_model\n","model_loaded = load_model(os.path.join(MODEL_DIR, model_name), compile=False)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["79/79 [==============================] - 9s 100ms/step\n","Test data classification report sklearn:\n","              precision    recall  f1-score   support\n","\n","         cov       0.80      1.00      0.89       177\n","        pneu       0.94      0.99      0.96       352\n","         reg       0.97      0.36      0.52        98\n","\n","    accuracy                           0.89       627\n","   macro avg       0.90      0.78      0.79       627\n","weighted avg       0.90      0.89      0.87       627\n","\n"]}],"source":["testX_exp=testX.copy()\n","testX_exp[:,:,:,0]=0\n","testX_exp[:,:,:,2]=0\n","\n","predIdxs = model.predict(testX_exp, batch_size=8)\n","predIdxs = np.argmax(predIdxs, axis=1)\n","print('Test data classification report sklearn:')\n","print(\n","    classification_report(\n","        testY.argmax(axis=1), predIdxs, target_names=lb.classes_\n","    )\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["40/40 [==============================] - 7s 171ms/step\n","Test data classification report sklearn:\n","              precision    recall  f1-score   support\n","\n","         cov       0.95      0.91      0.93       177\n","        pneu       0.99      0.98      0.98       352\n","         reg       0.78      0.88      0.83        98\n","\n","    accuracy                           0.94       627\n","   macro avg       0.91      0.92      0.91       627\n","weighted avg       0.95      0.94      0.94       627\n","\n"]}],"source":["testX_exp=testX.copy()\n","testX_exp[:,:,:,0]=testX_exp[:,:,:,1]\n","testX_exp[:,:,:,2]=testX_exp[:,:,:,1]\n","\n","predIdxs = model.predict(testX_exp, batch_size=BATCH_SIZE)\n","predIdxs = np.argmax(predIdxs, axis=1)\n","print('Test data classification report sklearn:')\n","print(\n","    classification_report(\n","        testY.argmax(axis=1), predIdxs, target_names=lb.classes_\n","    )\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
